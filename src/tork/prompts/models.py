"""Data models for the Agent-Selectable Prompts system."""

from datetime import datetime
from enum import Enum
from typing import Any, Dict, List
from uuid import uuid4
from pydantic import BaseModel, Field


class PromptType(str, Enum):
    """Types of prompts."""

    SYSTEM = "system"
    USER = "user"
    ASSISTANT = "assistant"
    CRITIQUE = "critique"
    SYNTHESIS = "synthesis"
    REFINEMENT = "refinement"
    EXPANSION = "expansion"
    COMPRESSION = "compression"


class PromptQuality(str, Enum):
    """Quality assessment of a prompt."""

    EXCELLENT = "excellent"
    GOOD = "good"
    ACCEPTABLE = "acceptable"
    POOR = "poor"
    REJECTED = "rejected"


class PromptCandidate(BaseModel):
    """A candidate prompt generated by an agent."""

    id: str = Field(default_factory=lambda: str(uuid4()))
    prompt_type: PromptType = Field(..., description="Type of prompt")
    content: str = Field(..., description="The prompt content")
    generator_agent: str = Field(..., description="Agent ID that generated this")
    generator_model: str = Field(default="", description="Model used")

    quality: PromptQuality = Field(default=PromptQuality.ACCEPTABLE)
    clarity_score: float = Field(default=0.5, ge=0.0, le=1.0)
    specificity_score: float = Field(default=0.5, ge=0.0, le=1.0)
    safety_score: float = Field(default=1.0, ge=0.0, le=1.0)

    token_count: int = Field(default=0)
    generation_time_ms: int = Field(default=0)
    metadata: Dict[str, Any] = Field(default_factory=dict)
    created_at: datetime = Field(default_factory=datetime.utcnow)


class PromptSelectionCriteria(BaseModel):
    """Criteria for selecting the best prompt."""

    min_clarity: float = Field(default=0.5, ge=0.0, le=1.0)
    min_specificity: float = Field(default=0.5, ge=0.0, le=1.0)
    min_safety: float = Field(default=0.8, ge=0.0, le=1.0)
    max_tokens: int = Field(default=4096, ge=1)

    preferred_generators: List[str] = Field(default_factory=list)
    blocked_generators: List[str] = Field(default_factory=list)
    prefer_quality: PromptQuality = Field(default=PromptQuality.GOOD)

    clarity_weight: float = Field(default=0.3, ge=0.0, le=1.0)
    specificity_weight: float = Field(default=0.3, ge=0.0, le=1.0)
    safety_weight: float = Field(default=0.4, ge=0.0, le=1.0)


class PromptSelectionResult(BaseModel):
    """Result of prompt selection."""

    selected: PromptCandidate = Field(..., description="The selected prompt")
    candidates: List[PromptCandidate] = Field(default_factory=list)
    selection_reasoning: str = Field(default="")
    confidence: float = Field(default=1.0, ge=0.0, le=1.0)
    total_evaluated: int = Field(default=0)
